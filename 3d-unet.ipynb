{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1lv7gPM7Cyd"
      },
      "source": [
        "# 3D U-Net for Kidney Tumor Segmentation\n",
        "\n",
        "This notebook implements a 3D U-Net model for kidney tumor segmentation using the KiTS23 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install segmentation_models_3D\n",
        "! pip install tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nibabel as nib\n",
        "import segmentation_models_3D as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG-ZLaeQ7Cyi"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! git clone https://github.com/neheller/kits23.git /content/kits23/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWDM2TOJ7Cyi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import shutil\n",
        "from time import sleep\n",
        "import concurrent.futures\n",
        "\n",
        "\n",
        "TRAINING_CASE_NUMBERS = list(range(300)) + list(range(400, 589))\n",
        "\n",
        "DST_PTH = Path(\"/content/kits23/dataset/\")\n",
        "\n",
        "\n",
        "def get_destination(case_id: str, create: bool = False):\n",
        "    destination = DST_PTH / case_id / \"imaging.nii.gz\"\n",
        "    if create:\n",
        "        destination.parent.mkdir(exist_ok=True)\n",
        "    return destination\n",
        "\n",
        "\n",
        "def cleanup(tmp_pth: Path, e: Exception):\n",
        "    if tmp_pth.exists():\n",
        "        tmp_pth.unlink()\n",
        "\n",
        "    if e is None:\n",
        "        print(\"\\nInterrupted.\\n\")\n",
        "        sys.exit()\n",
        "    raise e\n",
        "\n",
        "\n",
        "def download_case(case_num: int, retry=True):\n",
        "    remote_name = f\"master_{case_num:05d}.nii.gz\"\n",
        "    url = f\"https://kits19.sfo2.digitaloceanspaces.com/{remote_name}\"\n",
        "    destination = get_destination(f\"case_{case_num:05d}\", create=True)\n",
        "    tmp_pth = destination.parent / f\".partial.{destination.name}\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, str(tmp_pth))\n",
        "        shutil.move(str(tmp_pth), str(destination))\n",
        "    except Exception as e:\n",
        "        if retry:\n",
        "            print(f\"\\nFailed to download case_{case_num:05d}. Retrying...\")\n",
        "            sleep(5)\n",
        "            return download_case(case_num, retry=False)\n",
        "        else:\n",
        "            cleanup(tmp_pth, e)\n",
        "    return case_num  # Return case number for progress tracking\n",
        "\n",
        "\n",
        "def download_dataset():\n",
        "    # Make output directory if it doesn't exist already\n",
        "    DST_PTH.mkdir(exist_ok=True)\n",
        "\n",
        "    # Determine which cases still need to be downloaded\n",
        "    left_to_download = []\n",
        "    for case_num in TRAINING_CASE_NUMBERS:\n",
        "        case_id = f\"case_{case_num:05d}\"\n",
        "        dst = get_destination(case_id)\n",
        "        if not dst.exists():\n",
        "            left_to_download.append(case_num)\n",
        "\n",
        "    print(f\"\\nFound {len(left_to_download)} cases to download\\n\")\n",
        "    # Use ThreadPoolExecutor to download multiple cases concurrently.\n",
        "    max_workers = 8  # adjust this number based on your network and system\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # Use tqdm to show overall progress\n",
        "        results = list(tqdm(executor.map(download_case, left_to_download), total=len(left_to_download)))\n",
        "    print(\"\\nAll cases downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1_72oy216IJ"
      },
      "source": [
        "# Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVm7SPsc7Cyj"
      },
      "source": [
        "# Preprocess Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4mSrNf87NPO"
      },
      "source": [
        "## Remove Instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the dataset directory\n",
        "kits23_path = \"/content/kits23/dataset\"  # Change this path if needed\n",
        "\n",
        "# Get all case directories\n",
        "case_dirs = sorted([d for d in os.listdir(kits23_path) if os.path.isdir(os.path.join(kits23_path, d))])\n",
        "\n",
        "# Count total files to process for accurate overall progress\n",
        "total_files = 0\n",
        "for case_dir in case_dirs:\n",
        "    case_path = os.path.join(kits23_path, case_dir)\n",
        "    instance_files = glob.glob(os.path.join(case_path, \"instances\", \"*.nii.gz\"))\n",
        "    total_files += len(instance_files)\n",
        "\n",
        "# Create a single progress bar for all files\n",
        "pbar = tqdm(total=total_files, desc=\"Deleting instance files\")\n",
        "\n",
        "# Iterate through each case directory\n",
        "for case_dir in case_dirs:\n",
        "    case_path = os.path.join(kits23_path, case_dir)\n",
        "\n",
        "    # Find all instance segmentation files\n",
        "    instance_files = glob.glob(os.path.join(case_path, \"instances\", \"*.nii.gz\"))\n",
        "\n",
        "    # Delete instance files\n",
        "    for file in instance_files:\n",
        "        try:\n",
        "            os.remove(file)\n",
        "            pbar.update(1)  # Update the progress bar\n",
        "            pbar.set_postfix(case=case_dir, file=os.path.basename(file))\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file}: {e}\")\n",
        "\n",
        "    # Remove the 'instances' folder if it's empty\n",
        "    instances_folder = os.path.join(case_path, \"instances\")\n",
        "    if os.path.exists(instances_folder) and not os.listdir(instances_folder):\n",
        "        try:\n",
        "            os.rmdir(instances_folder)\n",
        "        except Exception as e:\n",
        "            print(f\"Error removing directory {instances_folder}: {e}\")\n",
        "\n",
        "pbar.close()\n",
        "print(\"Instance segmentation files deleted successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLZWVzuw7Cyj"
      },
      "source": [
        "## Downsize and Decompress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgJGn0sO7Cyj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_file(gz_path, target_shape=(96, 96, 96), image_order=1, label_order=0):\n",
        "    \"\"\"\n",
        "    Processes a single .nii.gz file:\n",
        "      - Loads it (on-the-fly decompression),\n",
        "      - Downsizes it to target_shape,\n",
        "      - Saves as an uncompressed .nii file,\n",
        "      - Removes the original .nii.gz.\n",
        "\n",
        "    Returns the new .nii file path.\n",
        "    \"\"\"\n",
        "    # Load the compressed file (decompressed in memory)\n",
        "    nifti_obj = nib.load(gz_path)\n",
        "    vol_data = nifti_obj.get_fdata(dtype=np.float32)\n",
        "    affine = nifti_obj.affine\n",
        "    header = nifti_obj.header\n",
        "\n",
        "    # Determine if file is a segmentation mask (for appropriate interpolation)\n",
        "    basename = os.path.basename(gz_path).lower()\n",
        "    is_segmentation = True #\"seg\" in basename or \"label\" in basename\n",
        "    interp_order = label_order if is_segmentation else image_order\n",
        "\n",
        "    # Get original spacing from header\n",
        "    pixdim = header.get_zooms()[:3]  # Get pixel dimensions (spacing)\n",
        "\n",
        "    # Calculate target spacing to maintain aspect ratio\n",
        "    orig_shape = vol_data.shape[:3]\n",
        "\n",
        "    # Option 1: Preserve aspect ratio based on smallest dimension\n",
        "    # This maintains the physical size relationship between dimensions\n",
        "    min_dim = np.argmin(orig_shape)\n",
        "    scale_factor = target_shape[min_dim] / orig_shape[min_dim]\n",
        "    new_shape = [int(round(s * scale_factor)) for s in orig_shape]\n",
        "\n",
        "    # Adjust to exactly match target shape in all dimensions\n",
        "    zoom_factors = [t / s for t, s in zip(target_shape, new_shape)]\n",
        "\n",
        "    # Option 2: Direct resizing (if you prefer ignoring aspect ratio)\n",
        "    # zoom_factors = [t / s for t, s in zip(target_shape, orig_shape)]\n",
        "\n",
        "    # Apply scipy's zoom function for resampling\n",
        "    # Important: Use order=0 for segmentation masks to prevent interpolation artifacts\n",
        "    # print(f\"Resizing {basename} from {orig_shape} to {target_shape} with order={interp_order}\")\n",
        "\n",
        "    # Apply resizing\n",
        "    vol_data_resized = zoom(vol_data, zoom_factors, order=interp_order, mode='nearest')\n",
        "\n",
        "    # Ensure exact target shape (sometimes zoom can be off by 1 pixel)\n",
        "    if vol_data_resized.shape[:3] != target_shape:\n",
        "        # Create a new array of target shape\n",
        "        final_vol = np.zeros(target_shape + vol_data_resized.shape[3:], dtype=vol_data_resized.dtype)\n",
        "        # Copy as much as fits\n",
        "        slices = tuple(slice(0, min(t, s)) for t, s in zip(target_shape, vol_data_resized.shape[:3]))\n",
        "        final_vol[slices] = vol_data_resized[slices]\n",
        "        vol_data_resized = final_vol\n",
        "\n",
        "    # For segmentation masks, ensure integer values are preserved\n",
        "    if is_segmentation:\n",
        "        vol_data_resized = np.round(vol_data_resized).astype(np.uint8)\n",
        "\n",
        "    # Update header with new dimensions\n",
        "    new_header = header.copy()\n",
        "    # Update the zooms/pixdim to reflect the new voxel size\n",
        "    new_zooms = tuple([p * o / t for p, o, t in zip(pixdim, orig_shape, target_shape)] + list(header.get_zooms()[3:]))\n",
        "    new_header.set_zooms(new_zooms)\n",
        "\n",
        "    # Save the downsized volume as an uncompressed .nii file (remove \".gz\" extension)\n",
        "    new_nii_path = gz_path[:-3]\n",
        "    downsized_nifti = nib.Nifti1Image(vol_data_resized, affine, new_header)\n",
        "    nib.save(downsized_nifti, new_nii_path)\n",
        "\n",
        "    # Remove the original .nii.gz file\n",
        "    os.remove(gz_path)\n",
        "\n",
        "    return new_nii_path\n",
        "\n",
        "def downsize_nii_gz_multithreaded(\n",
        "    root_dir,\n",
        "    target_shape=(128, 128, 128),\n",
        "    image_order=1,\n",
        "    label_order=0,\n",
        "    max_workers=4\n",
        "):\n",
        "    \"\"\"\n",
        "    Finds all .nii.gz files under 'root_dir' and processes them in parallel.\n",
        "    \"\"\"\n",
        "    # Gather all .nii.gz file paths from the directory tree.\n",
        "    gz_files = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(\".nii.gz\"):\n",
        "                gz_files.append(os.path.join(dirpath, filename))\n",
        "\n",
        "    print(f\"Found {len(gz_files)} .nii.gz files to process.\")\n",
        "\n",
        "    # Use ProcessPoolExecutor to process files in parallel.\n",
        "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = {\n",
        "            executor.submit(process_file, gz_path, target_shape, image_order, label_order): gz_path\n",
        "            for gz_path in gz_files\n",
        "        }\n",
        "\n",
        "        # Use tqdm to show progress\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(gz_files), desc=\"Processing files\"):\n",
        "            try:\n",
        "                result = future.result()\n",
        "            except Exception as exc:\n",
        "                print(f\"File processing generated an exception: {exc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DezedJnM7Cyk",
        "outputId": "f0bd6839-2beb-439a-8a69-d22bd65eb655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 980 .nii.gz files to process.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 980/980 [06:45<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All .nii.gz files processed: downsized and saved as .nii.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "kits23_root = \"/content/kits23/dataset\"  # adjust this path as needed\n",
        "# Example: downsize all volumes to 96x96x96; adjust max_workers based on your CPU cores.\n",
        "downsize_nii_gz_multithreaded(kits23_root, target_shape=(128, 128, 128), max_workers=8)\n",
        "print(\"All .nii.gz files processed: downsized and saved as .nii.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0htgc9r7Cyk"
      },
      "source": [
        "## Delete Label 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "ROOT_DIR = \"/content/kits23/dataset/\" # Change to your dataset path\n",
        "DRY_RUN = False # Set to True to preview without changes\n",
        "MAX_WORKERS = 8 # Number of parallel workers\n",
        "\n",
        "def delete_last_label(file_path, dry_run=False):\n",
        "    \"\"\"\n",
        "    Function to delete the last label in a 3D segmentation file, keeping only the first two labels.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        file_path = Path(file_path)\n",
        "        case_name = file_path.parent.name\n",
        "\n",
        "        # Load the segmentation file\n",
        "        seg_img = nib.load(file_path)\n",
        "        seg_data = seg_img.get_fdata()\n",
        "\n",
        "        # Get unique labels in the segmentation\n",
        "        unique_labels = np.unique(seg_data)\n",
        "\n",
        "        # If there are fewer than 3 labels, no action needed\n",
        "        if len(unique_labels) < 3:\n",
        "            return {\n",
        "                'case_name': case_name,\n",
        "                'filename': file_path.name,\n",
        "                'modified': False,\n",
        "                'message': 'Fewer than 3 labels present'\n",
        "            }\n",
        "\n",
        "        # Identify the last label\n",
        "        last_label = unique_labels[-1]\n",
        "\n",
        "        # Count voxels that will be deleted\n",
        "        voxels_to_delete = np.sum(seg_data == last_label)\n",
        "\n",
        "        # Create modified data by zeroing out the last label\n",
        "        modified_data = seg_data.copy()\n",
        "        modified_data[modified_data == last_label] = 0\n",
        "\n",
        "        # Save if not dry run\n",
        "        if not dry_run:\n",
        "            modified_img = nib.Nifti1Image(modified_data, seg_img.affine, seg_img.header)\n",
        "            nib.save(modified_img, str(file_path))\n",
        "\n",
        "        return {\n",
        "            'case_name': case_name,\n",
        "            'filename': file_path.name,\n",
        "            'modified': True,\n",
        "            'last_label': int(last_label),\n",
        "            'voxels_deleted': int(voxels_to_delete)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'case_name': file_path.parent.name if isinstance(file_path, Path) else os.path.basename(os.path.dirname(file_path)),\n",
        "            'filename': file_path.name if isinstance(file_path, Path) else os.path.basename(file_path),\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # Find all segmentation files (supporting .nii and .nii.gz)\n",
        "    root_dir = Path(ROOT_DIR)\n",
        "    seg_files = list(root_dir.glob(\"**/segmentation.nii*\"))\n",
        "\n",
        "    if not seg_files:\n",
        "        print(f\"No segmentation files found in {ROOT_DIR}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(seg_files)} segmentation files to process\")\n",
        "\n",
        "    # Process files in parallel\n",
        "    results = []\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        futures = [executor.submit(delete_last_label, file_path, DRY_RUN) for file_path in seg_files]\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing files\"):\n",
        "            result = future.result()\n",
        "            results.append(result)\n",
        "\n",
        "    # Print summary\n",
        "    files_modified = sum(1 for r in results if r.get('modified', False))\n",
        "    files_with_errors = sum(1 for r in results if 'error' in r)\n",
        "    total_voxels_deleted = sum(r.get('voxels_deleted', 0) for r in results if r.get('modified', False))\n",
        "\n",
        "    print(\"\\n=== SUMMARY ===\")\n",
        "    print(f\"Total files processed: {len(results)}\")\n",
        "    print(f\"Files modified (last label deleted): {files_modified}\")\n",
        "    print(f\"Total voxels deleted: {total_voxels_deleted}\")\n",
        "    print(f\"Files with errors: {files_with_errors}\")\n",
        "\n",
        "    if files_with_errors > 0:\n",
        "        print(\"\\nErrors:\")\n",
        "        for r in results:\n",
        "            if 'error' in r:\n",
        "                print(f\" - {r['case_name']}/{r['filename']}: {r['error']}\")\n",
        "\n",
        "    if DRY_RUN:\n",
        "        print(\"\\nThis was a DRY RUN. No files were actually modified.\")\n",
        "        print(\"Set DRY_RUN = False to save changes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUeUPIgd7Cyk"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "445cHbOD7Cyl"
      },
      "source": [
        "## Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdtN-7q67Cyl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def check_dataset_files(dataset_path):\n",
        "    \"\"\"\n",
        "    Check a dataset directory for .nii or .nii.gz files, analyze file patterns,\n",
        "    and identify missing files in each case folder.\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to the dataset directory containing case folders\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with analysis results\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure dataset_path exists\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise FileNotFoundError(f\"Dataset path not found: {dataset_path}\")\n",
        "\n",
        "    # Lists to track various conditions\n",
        "    case_folders = []\n",
        "    total_nii_files = 0\n",
        "    total_nii_gz_files = 0\n",
        "    case_file_counts = {}\n",
        "    common_filenames = set()\n",
        "    missing_imaging = []\n",
        "    missing_segmentation = []\n",
        "\n",
        "    # Get all case folders\n",
        "    case_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
        "\n",
        "    print(f\"Found {len(case_folders)} case folders to check\")\n",
        "\n",
        "    # Check each case folder for files\n",
        "    for case_folder in case_folders:\n",
        "        case_path = os.path.join(dataset_path, case_folder)\n",
        "        files = os.listdir(case_path)\n",
        "\n",
        "        # Count different file types\n",
        "        nii_files = [f for f in files if f.endswith('.nii')]\n",
        "        nii_gz_files = [f for f in files if f.endswith('.nii.gz')]\n",
        "\n",
        "        # Track filenames to identify patterns\n",
        "        for f in nii_files + nii_gz_files:\n",
        "            base_name = f.split('.')[0]  # Get name without extension\n",
        "            common_filenames.add(base_name)\n",
        "\n",
        "        # Update totals\n",
        "        total_nii_files += len(nii_files)\n",
        "        total_nii_gz_files += len(nii_gz_files)\n",
        "        case_file_counts[case_folder] = {\n",
        "            'nii': len(nii_files),\n",
        "            'nii_gz': len(nii_gz_files),\n",
        "            'total': len(nii_files) + len(nii_gz_files)\n",
        "        }\n",
        "\n",
        "        # Check for specific files (both .nii and .nii.gz versions)\n",
        "        has_imaging = any(f == \"imaging.nii\" or f == \"imaging.nii.gz\" for f in files)\n",
        "        has_segmentation = any(f == \"segmentation.nii\" or f == \"segmentation.nii.gz\" for f in files)\n",
        "\n",
        "        if not has_imaging:\n",
        "            missing_imaging.append(case_folder)\n",
        "        if not has_segmentation:\n",
        "            missing_segmentation.append(case_folder)\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Total .nii files found: {total_nii_files}\")\n",
        "    print(f\"Total .nii.gz files found: {total_nii_gz_files}\")\n",
        "    print(f\"Combined total: {total_nii_files + total_nii_gz_files}\")\n",
        "    print(f\"Expected total (if all cases have 2 files): {len(case_folders) * 2}\")\n",
        "    print(f\"Common filenames in dataset: {sorted(common_filenames)}\")\n",
        "    print(f\"Cases missing imaging files: {len(missing_imaging)}\")\n",
        "    print(f\"Cases missing segmentation files: {len(missing_segmentation)}\")\n",
        "\n",
        "    # Find cases with abnormal file counts\n",
        "    abnormal_cases = {case: info for case, info in case_file_counts.items() if info['total'] != 2}\n",
        "    print(f\"Cases with != 2 files: {len(abnormal_cases)}\")\n",
        "\n",
        "    return {\n",
        "        \"total_cases\": len(case_folders),\n",
        "        \"total_nii_files\": total_nii_files,\n",
        "        \"total_nii_gz_files\": total_nii_gz_files,\n",
        "        \"common_filenames\": sorted(common_filenames),\n",
        "        \"missing_imaging\": missing_imaging,\n",
        "        \"missing_segmentation\": missing_segmentation,\n",
        "        \"abnormal_cases\": abnormal_cases\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = check_dataset_files('/content/kits23/dataset')\n",
        "\n",
        "print(\"\\nCases with abnormal file counts:\")\n",
        "for case, info in sorted(results[\"abnormal_cases\"].items()):\n",
        "  print(f\" - {case}: {info}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvxrCp8P7Cyl"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gt-w0KA7Cyl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import nibabel as nib\n",
        "\n",
        "\n",
        "class KiTS23Dataset:\n",
        "    def __init__(self, dataset_path, target_shape=(96, 96, 96), use_cache=True, cache_limit=50):\n",
        "        \"\"\"\n",
        "        Initialize the KiTS23 dataset loader\n",
        "\n",
        "        Args:\n",
        "            dataset_path (str): Path to the KiTS23 dataset\n",
        "            target_shape (tuple): Target shape for the 3D volumes (will be resized)\n",
        "            use_cache (bool): Whether to cache loaded data in memory\n",
        "            cache_limit (int): Maximum number of cases to cache in memory\n",
        "        \"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.target_shape = target_shape\n",
        "        self.use_cache = use_cache\n",
        "        self.cache_limit = cache_limit\n",
        "        self.cache = {}\n",
        "\n",
        "        # Find all case directories\n",
        "        self.cases = []\n",
        "        for item in os.listdir(dataset_path):\n",
        "            case_dir = os.path.join(dataset_path, item)\n",
        "            if os.path.isdir(case_dir):\n",
        "                # Check if both imaging and segmentation files exist\n",
        "                imaging_file = os.path.join(case_dir, \"imaging.nii.gz\")\n",
        "                imaging_alt = os.path.join(case_dir, \"imaging.nii\")\n",
        "\n",
        "                segmentation_file = os.path.join(case_dir, \"segmentation.nii.gz\")\n",
        "                segmentation_alt = os.path.join(case_dir, \"segmentation.nii\")\n",
        "\n",
        "                if (os.path.exists(imaging_file) or os.path.exists(imaging_alt)) and \\\n",
        "                   (os.path.exists(segmentation_file) or os.path.exists(segmentation_alt)):\n",
        "                    self.cases.append(item)\n",
        "\n",
        "        print(f\"Found {len(self.cases)} valid cases with both imaging and segmentation data\")\n",
        "\n",
        "        # Get label statistics\n",
        "        self.all_labels = self._get_all_labels()\n",
        "        print(f\"Found {len(self.all_labels)} unique labels: {sorted(list(self.all_labels))}\")\n",
        "\n",
        "\n",
        "    def _get_all_labels(self):\n",
        "        \"\"\"Get all unique labels in the segmentation files\"\"\"\n",
        "        all_labels = set()\n",
        "        for case in tqdm(self.cases[:min(10, len(self.cases))], desc=\"Analyzing labels\"):\n",
        "            seg_file = self._get_segmentation_path(case)\n",
        "            if seg_file:\n",
        "                try:\n",
        "                    seg_data = self._load_nifti(seg_file)\n",
        "                    unique_labels = np.unique(np.round(seg_data).astype(int))\n",
        "                    all_labels.update(unique_labels)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {seg_file}: {e}\")\n",
        "\n",
        "        return all_labels\n",
        "\n",
        "    def _get_imaging_path(self, case_id):\n",
        "        \"\"\"Get path to imaging file for a case\"\"\"\n",
        "        for ext in [\".nii.gz\", \".nii\"]:\n",
        "            path = os.path.join(self.dataset_path, case_id, f\"imaging{ext}\")\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        return None\n",
        "\n",
        "    def _get_segmentation_path(self, case_id):\n",
        "        \"\"\"Get path to segmentation file for a case\"\"\"\n",
        "        for ext in [\".nii.gz\", \".nii\"]:\n",
        "            path = os.path.join(self.dataset_path, case_id, f\"segmentation{ext}\")\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        return None\n",
        "\n",
        "    def _load_nifti(self, file_path):\n",
        "        \"\"\"Load a NIfTI file and return the data array\"\"\"\n",
        "        img = nib.load(file_path)\n",
        "        return img.get_fdata()\n",
        "\n",
        "\n",
        "    def _resize_volume(self, volume, target_shape=None):\n",
        "        \"\"\"Resize a 3D volume to target shape\"\"\"\n",
        "        if target_shape is None:\n",
        "            target_shape = self.target_shape\n",
        "\n",
        "        # Get current shape\n",
        "        current_shape = volume.shape\n",
        "\n",
        "        # Calculate resize factors\n",
        "        resize_factor = [target_shape[i] / current_shape[i] for i in range(3)]\n",
        "\n",
        "        # Use scipy zoom for 3D resizing\n",
        "        from scipy.ndimage import zoom\n",
        "        resized_volume = zoom(volume, resize_factor, order=0 if len(volume.shape) == 3 else [0, 0, 0, 1])\n",
        "\n",
        "        return resized_volume\n",
        "\n",
        "    def _preprocess_volume(self, volume, is_mask=False):\n",
        "      \"\"\"Preprocess a volume by resizing and normalizing\"\"\"\n",
        "      volume = np.array(volume)\n",
        "\n",
        "      if is_mask:\n",
        "          # Process masks normally\n",
        "          volume = np.round(volume).astype(np.uint8)\n",
        "          num_classes = len(self.all_labels)\n",
        "\n",
        "          # Convert to one-hot encoding\n",
        "          mask_classes = np.zeros(self.target_shape + (num_classes,), dtype=np.float32)\n",
        "          for i, label in enumerate(sorted(self.all_labels)):\n",
        "              mask_classes[..., i] = (volume == label).astype(np.float32)\n",
        "\n",
        "          return mask_classes\n",
        "      else:\n",
        "          # Normalize image\n",
        "          window_center = 30\n",
        "          window_width = 400\n",
        "          window_min = window_center - window_width // 2\n",
        "          window_max = window_center + window_width // 2\n",
        "\n",
        "          volume = np.clip(volume, window_min, window_max)\n",
        "          volume = (volume - window_min) / (window_max - window_min)\n",
        "\n",
        "          # ðŸš€ **Fix: Ensure 3 channels**\n",
        "          if len(volume.shape) == 3:\n",
        "              volume = np.expand_dims(volume, axis=-1)  # (96, 96, 96, 1)\n",
        "              volume = np.repeat(volume, 3, axis=-1)    # (96, 96, 96, 3)\n",
        "\n",
        "          return volume.astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def load_case(self, case_id):\n",
        "        \"\"\"\n",
        "        Load imaging and segmentation data for a specific case\n",
        "\n",
        "        Args:\n",
        "            case_id (str): Case identifier\n",
        "\n",
        "        Returns:\n",
        "            tuple: (imaging_data, segmentation_data)\n",
        "        \"\"\"\n",
        "        if self.use_cache and case_id in self.cache:\n",
        "            return self.cache[case_id]\n",
        "\n",
        "        imaging_path = self._get_imaging_path(case_id)\n",
        "        segmentation_path = self._get_segmentation_path(case_id)\n",
        "\n",
        "        if not imaging_path or not segmentation_path:\n",
        "            raise ValueError(f\"Could not find imaging or segmentation files for case {case_id}\")\n",
        "\n",
        "        # Load data\n",
        "        imaging_data = self._load_nifti(imaging_path)\n",
        "        segmentation_data = self._load_nifti(segmentation_path)\n",
        "\n",
        "        # Preprocess\n",
        "        imaging_processed = self._preprocess_volume(imaging_data)\n",
        "        segmentation_processed = self._preprocess_volume(segmentation_data, is_mask=True)\n",
        "\n",
        "        result = (imaging_processed, segmentation_processed)\n",
        "\n",
        "        if self.use_cache:\n",
        "            # Manage cache size\n",
        "            if len(self.cache) >= self.cache_limit:\n",
        "                # Remove a random item from cache\n",
        "                remove_key = random.choice(list(self.cache.keys()))\n",
        "                del self.cache[remove_key]\n",
        "\n",
        "            self.cache[case_id] = result\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    def _augment_pair(self, image, mask):\n",
        "      return image, mask\n",
        "\n",
        "\n",
        "\n",
        "    def batch_generator(self, case_ids, batch_size, preprocess_fn=None, augment=False):\n",
        "      \"\"\"Generator function to yield batches of data\"\"\"\n",
        "      while True:\n",
        "          # Shuffle cases for each epoch\n",
        "          random.shuffle(case_ids)\n",
        "\n",
        "          # Generate batches\n",
        "          for i in range(0, len(case_ids), batch_size):\n",
        "              batch_cases = case_ids[i:i+batch_size]\n",
        "\n",
        "              images = []\n",
        "              masks = []\n",
        "\n",
        "              for case_id in batch_cases:\n",
        "                  try:\n",
        "                      image, mask = self.load_case(case_id)\n",
        "\n",
        "                      if augment:\n",
        "                          # Apply random augmentations\n",
        "                          image, mask = self._augment_pair(image, mask)\n",
        "\n",
        "                      images.append(image)\n",
        "                      masks.append(mask)\n",
        "                  except Exception as e:\n",
        "                      print(f\"Error loading case {case_id}: {e}\")\n",
        "                      continue\n",
        "\n",
        "              if not images:\n",
        "                  continue\n",
        "\n",
        "              # Convert to numpy arrays\n",
        "              if len(images) > 0:\n",
        "                  expected_shape = images[0].shape  # Get the expected shape from the first image\n",
        "\n",
        "                  # FIX: Proper resizing for mismatched shapes\n",
        "                  for j in range(len(images)):\n",
        "                      if images[j].shape != expected_shape:\n",
        "                          # Use the proper resize method instead of np.resize\n",
        "                          images[j] = self._resize_volume(images[j], expected_shape[:3])\n",
        "\n",
        "                      if masks[j].shape != expected_shape:\n",
        "                          # For masks, use order=0 to preserve label values (no interpolation)\n",
        "                          masks[j] = self._resize_volume(masks[j], expected_shape[:3])\n",
        "\n",
        "                  # Now convert to numpy arrays after proper resizing\n",
        "                  images = np.array(images)\n",
        "                  masks = np.array(masks)\n",
        "\n",
        "              # Apply preprocessing function if provided\n",
        "              if preprocess_fn:\n",
        "                  images = preprocess_fn(images)\n",
        "\n",
        "              yield images, masks\n",
        "\n",
        "    def create_tf_datasets(self, batch_size=2, validation_split=0.2, test_split=0.1, preprocess_fn=None):\n",
        "      \"\"\"Create train, validation, and test datasets\"\"\"\n",
        "      # Handle None test_split case\n",
        "      if test_split is None or test_split == 0:\n",
        "          # No test split, only train/validation\n",
        "          train_cases, val_cases = train_test_split(self.cases, test_size=validation_split, random_state=42)\n",
        "          test_cases = []  # Empty test set\n",
        "      else:\n",
        "          # Normal case with test split\n",
        "          train_cases, test_cases = train_test_split(self.cases, test_size=test_split, random_state=42)\n",
        "          train_cases, val_cases = train_test_split(train_cases, test_size=validation_split/(1-test_split), random_state=42)\n",
        "\n",
        "      print(f\"Train: {len(train_cases)} cases, Validation: {len(val_cases)} cases, Test: {len(test_cases)} cases\")\n",
        "\n",
        "      # Create generators\n",
        "      train_gen = self.batch_generator(train_cases, batch_size, preprocess_fn, augment=False)\n",
        "      val_gen = self.batch_generator(val_cases, batch_size, preprocess_fn, augment=False)\n",
        "\n",
        "      # Create test generator only if we have test cases\n",
        "      test_gen = None\n",
        "      if test_cases:\n",
        "          test_gen = self.batch_generator(test_cases, batch_size, preprocess_fn, augment=False)\n",
        "\n",
        "      # Calculate steps per epoch\n",
        "      steps_per_epoch = max(1, len(train_cases) // batch_size)\n",
        "      validation_steps = max(1, len(val_cases) // batch_size)\n",
        "      test_steps = max(1, len(test_cases) // batch_size) if test_cases else 0\n",
        "\n",
        "      return train_gen, val_gen, test_gen, steps_per_epoch, validation_steps, test_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiujfGAG7Cym"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_3D as sm\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJpv8fr7SsL"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRQ9AAyO7Wqc"
      },
      "outputs": [],
      "source": [
        "# Dice coefficient without background\n",
        "def kidney_tumor_dice(y_true, y_pred):\n",
        "    # Remove background channel (assuming it's index 0)\n",
        "    y_true_no_bg = y_true[..., 1:]  # Kidney and tumor only\n",
        "    y_pred_no_bg = y_pred[..., 1:]  # Kidney and tumor only\n",
        "\n",
        "    # Calculate Dice\n",
        "    intersection = tf.reduce_sum(y_true_no_bg * y_pred_no_bg, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true_no_bg, axis=[1, 2, 3]) + tf.reduce_sum(y_pred_no_bg, axis=[1, 2, 3])\n",
        "\n",
        "    # Add smooth factor for stability\n",
        "    smooth = 1e-6\n",
        "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return tf.reduce_mean(dice)\n",
        "\n",
        "# IoU/Jaccard without background\n",
        "def kidney_tumor_iou(y_true, y_pred):\n",
        "    # Remove background channel\n",
        "    y_true_no_bg = y_true[..., 1:]\n",
        "    y_pred_no_bg = y_pred[..., 1:]\n",
        "\n",
        "    # Calculate IoU\n",
        "    intersection = tf.reduce_sum(y_true_no_bg * y_pred_no_bg, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true_no_bg, axis=[1, 2, 3]) + tf.reduce_sum(y_pred_no_bg, axis=[1, 2, 3]) - intersection\n",
        "\n",
        "    # Add smooth factor\n",
        "    smooth = 1e-6\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return tf.reduce_mean(iou)\n",
        "\n",
        "# You can also calculate per-class metrics\n",
        "def kidney_dice(y_true, y_pred):\n",
        "    # Extract kidney channel (assuming it's index 1)\n",
        "    y_true_kidney = y_true[..., 1]\n",
        "    y_pred_kidney = y_pred[..., 1]\n",
        "\n",
        "    # Calculate Dice for kidney\n",
        "    intersection = tf.reduce_sum(y_true_kidney * y_pred_kidney, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true_kidney, axis=[1, 2, 3]) + tf.reduce_sum(y_pred_kidney, axis=[1, 2, 3])\n",
        "\n",
        "    smooth = 1e-6\n",
        "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return tf.reduce_mean(dice)\n",
        "\n",
        "def tumor_dice(y_true, y_pred):\n",
        "    # Extract tumor channel (assuming it's index 2)\n",
        "    y_true_tumor = y_true[..., 2]\n",
        "    y_pred_tumor = y_pred[..., 2]\n",
        "\n",
        "    # Calculate Dice for tumor\n",
        "    intersection = tf.reduce_sum(y_true_tumor * y_pred_tumor, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true_tumor, axis=[1, 2, 3]) + tf.reduce_sum(y_pred_tumor, axis=[1, 2, 3])\n",
        "\n",
        "    smooth = 1e-6\n",
        "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return tf.reduce_mean(dice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdD7ZpbL7lUv"
      },
      "outputs": [],
      "source": [
        "# Modified volumetric similarity focused on kidney and tumor\n",
        "def kidney_tumor_vol_sim(y_true, y_pred):\n",
        "    # Remove background\n",
        "    y_true_no_bg = y_true[..., 1:]\n",
        "    y_pred_no_bg = K.cast(K.greater(y_pred[..., 1:], 0.5), 'float32')\n",
        "\n",
        "    # Calculate volumes\n",
        "    vol_true = K.sum(y_true_no_bg, axis=[1, 2, 3])\n",
        "    vol_pred = K.sum(y_pred_no_bg, axis=[1, 2, 3])\n",
        "\n",
        "    # Calculate volumetric similarity with handling for empty volumes\n",
        "    epsilon = K.epsilon()\n",
        "    vs = 1.0 - K.abs(vol_true - vol_pred) / (vol_true + vol_pred + epsilon)\n",
        "\n",
        "    # Average over batch and classes\n",
        "    return K.mean(vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ4WPFc17vCX"
      },
      "outputs": [],
      "source": [
        "def kidney_tumor_hausdorff(y_true, y_pred, max_dist=100.0):\n",
        "    \"\"\"\n",
        "    Calculate approximate Hausdorff distance for kidney and tumor classes only\n",
        "    \"\"\"\n",
        "    # Process only kidney and tumor channels (skip background)\n",
        "    y_true_no_bg = y_true[..., 1:]  # Kidney and tumor only\n",
        "    y_pred_no_bg = y_pred[..., 1:]  # Kidney and tumor only\n",
        "\n",
        "    # Convert predictions to binary\n",
        "    y_pred_binary = K.cast(K.greater(y_pred_no_bg, 0.5), 'float32')\n",
        "    y_true_binary = K.cast(y_true_no_bg, 'float32')\n",
        "\n",
        "    # Function to compute Hausdorff approximation\n",
        "    def _hausdorff(y_t_p):\n",
        "        y_t, y_p = y_t_p  # Unpack tuple\n",
        "\n",
        "        # Find positive pixels for each class independently\n",
        "        hausdorff_distances = []\n",
        "\n",
        "        # Loop through kidney and tumor classes\n",
        "        for c in range(K.int_shape(y_t)[-1]):  # Either 2 classes (kidney, tumor)\n",
        "            # Extract single class\n",
        "            y_t_class = y_t[..., c]\n",
        "            y_p_class = y_p[..., c]\n",
        "\n",
        "            # Find positive pixels\n",
        "            y_t_pos = K.cast(K.greater(y_t_class, 0.5), 'float32')\n",
        "            y_p_pos = K.cast(K.greater(y_p_class, 0.5), 'float32')\n",
        "\n",
        "            # Compute sums to check if this class exists in this sample\n",
        "            sum_t = K.sum(y_t_pos)\n",
        "            sum_p = K.sum(y_p_pos)\n",
        "\n",
        "            # If either set is empty, use max_dist for this class\n",
        "            class_dist = tf.cond(\n",
        "                tf.logical_or(tf.equal(sum_t, 0), tf.equal(sum_p, 0)),\n",
        "                lambda: tf.constant(max_dist, dtype=tf.float32),\n",
        "                lambda: _compute_hausdorff(y_t_pos, y_p_pos, max_dist)\n",
        "            )\n",
        "\n",
        "            hausdorff_distances.append(class_dist)\n",
        "\n",
        "        # Return mean of distances across classes\n",
        "        return tf.reduce_mean(hausdorff_distances)\n",
        "\n",
        "    def _compute_hausdorff(y_t_pos, y_p_pos, max_dist):\n",
        "        # Flatten tensors\n",
        "        y_t_pos_flat = K.flatten(y_t_pos)\n",
        "        y_p_pos_flat = K.flatten(y_p_pos)\n",
        "\n",
        "        # Compute precision and recall (efficient approximation)\n",
        "        precision = K.sum(y_p_pos_flat * y_t_pos_flat) / (K.sum(y_p_pos_flat) + K.epsilon())\n",
        "        recall = K.sum(y_p_pos_flat * y_t_pos_flat) / (K.sum(y_t_pos_flat) + K.epsilon())\n",
        "\n",
        "        # Approximate Hausdorff distance\n",
        "        approx_hausdorff = max_dist * (2 - precision - recall)\n",
        "        return approx_hausdorff\n",
        "\n",
        "    # Apply function over batch\n",
        "    return K.mean(tf.map_fn(lambda y_t_p: _hausdorff(y_t_p), (y_true_binary, y_pred_binary), dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2wHYKxF7S8F"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiQrww8R7Cym"
      },
      "outputs": [],
      "source": [
        "def get_model_memory_usage(batch_size, model):\n",
        "    \"\"\"Calculate approximate GPU memory usage of a model in GB\"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "        from keras import backend as K\n",
        "\n",
        "        # Function to count parameters\n",
        "        def count_params(weights):\n",
        "            return sum(np.prod(w.shape) for w in weights)\n",
        "\n",
        "        # Get trainable and non-trainable params\n",
        "        trainable_count = count_params(model.trainable_weights)\n",
        "        non_trainable_count = count_params(model.non_trainable_weights)\n",
        "\n",
        "        # Calculate activation memory\n",
        "        shapes_mem_count = 0\n",
        "        internal_model_mem_count = 0\n",
        "        for l in model.layers:\n",
        "            layer_type = l.__class__.__name__\n",
        "\n",
        "            # Skip input layers or handle them specially\n",
        "            if layer_type == 'InputLayer':\n",
        "                continue\n",
        "\n",
        "            if layer_type == 'Model' or layer_type == 'Functional':\n",
        "                internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
        "                continue\n",
        "\n",
        "            # Get the output shape\n",
        "            single_layer_mem = 1\n",
        "            try:\n",
        "                # Try different attribute names for output shape\n",
        "                if hasattr(l, 'output_shape'):\n",
        "                    out_shape = l.output_shape\n",
        "                elif hasattr(l, 'output'):\n",
        "                    out_shape = l.output.shape\n",
        "                elif hasattr(l, '_output_shape'):\n",
        "                    out_shape = l._output_shape\n",
        "                else:\n",
        "                    # If we can't determine the output shape, make a conservative estimate\n",
        "                    print(f\"Warning: Could not determine output shape for layer {l.name}\")\n",
        "                    continue\n",
        "\n",
        "                # Handle lists of shapes (multiple outputs)\n",
        "                if isinstance(out_shape, list):\n",
        "                    out_shape = out_shape[0]\n",
        "\n",
        "                # Calculate memory for this layer's activations\n",
        "                for s in out_shape:\n",
        "                    if s is None:\n",
        "                        continue\n",
        "                    single_layer_mem *= s\n",
        "\n",
        "                shapes_mem_count += single_layer_mem\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error processing layer {l.name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Determine size of each parameter based on dtype\n",
        "        number_size = 4.0  # Default float32\n",
        "        if K.floatx() == 'float16':\n",
        "            number_size = 2.0\n",
        "        if K.floatx() == 'float64':\n",
        "            number_size = 8.0\n",
        "\n",
        "        # Calculate total memory\n",
        "        total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
        "        gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
        "        return gbytes\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating model memory usage: {e}\")\n",
        "        return \"Memory estimation failed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoLfJk7x7Cym"
      },
      "outputs": [],
      "source": [
        "def train_kits23_model(dataset_path, output_dir=\"models\", model_name=\"kits23_unet\",\n",
        "                       batch_size=2, epochs=50, learning_rate=0.0001, patience=10,\n",
        "                       backbone=\"resnet18\", target_shape=(96, 96, 96)):\n",
        "    \"\"\"\n",
        "    Train a 3D U-Net model on KiTS23 dataset with additional evaluation metrics\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to the KiTS23 dataset\n",
        "        output_dir (str): Directory to save models and logs\n",
        "        model_name (str): Base name for the model files\n",
        "        batch_size (int): Batch size for training\n",
        "        epochs (int): Number of training epochs\n",
        "        learning_rate (float): Initial learning rate\n",
        "        patience (int): Patience for early stopping\n",
        "        backbone (str): Backbone architecture for the U-Net\n",
        "        target_shape (tuple): Target shape for the input volumes\n",
        "    \"\"\"\n",
        "    #from tensorflow.keras.mixed_precision import set_global_policy\n",
        "    #set_global_policy('mixed_float16')\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize dataset\n",
        "    dataset = KiTS23Dataset(\n",
        "        dataset_path=dataset_path,\n",
        "        target_shape=target_shape,\n",
        "        use_cache=True,\n",
        "        cache_limit=50\n",
        "    )\n",
        "\n",
        "    # Get number of classes\n",
        "    num_classes = len(dataset.all_labels)\n",
        "    print(f\"Training model with {num_classes} classes\")\n",
        "\n",
        "    # Get preprocessing function for the backbone\n",
        "    preprocess_input = sm.get_preprocessing(backbone)\n",
        "\n",
        "    # Create dataset generators\n",
        "    train_gen, val_gen, test_gen, steps_per_epoch, validation_steps, _ = dataset.create_tf_datasets(\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.2,\n",
        "        test_split=0,\n",
        "        preprocess_fn=preprocess_input\n",
        "    )\n",
        "\n",
        "    # Setup model\n",
        "    shape_size = (*target_shape, 3)  # 3 channels\n",
        "    encoder_weights = 'imagenet'\n",
        "\n",
        "    # Create model\n",
        "    model = sm.Unet(\n",
        "        backbone,\n",
        "        input_shape=shape_size,\n",
        "        encoder_weights=encoder_weights,\n",
        "        classes=num_classes,\n",
        "    )\n",
        "\n",
        "    # Display model summary and memory usage\n",
        "    print(model.summary())\n",
        "    print(f\"Estimated GPU memory usage: {get_model_memory_usage(batch_size, model)} GB\")\n",
        "\n",
        "    # Setup optimizer and loss\n",
        "    lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
        "        initial_learning_rate=learning_rate,\n",
        "        first_decay_steps=steps_per_epoch * 5,\n",
        "        t_mul=1.5,\n",
        "        m_mul=0.95,\n",
        "        alpha=0.001\n",
        "    )\n",
        "\n",
        "    optim = AdamW(\n",
        "        learning_rate=lr_schedule,\n",
        "        weight_decay=1e-5,\n",
        "        clipnorm=1.0\n",
        "    )\n",
        "\n",
        "    def kidney_tumor_only_loss(y_true, y_pred, gamma=0.75):\n",
        "      \"\"\"\n",
        "      Focal Tversky loss that only considers kidney and tumor classes\n",
        "      \"\"\"\n",
        "      # Remove background channel (assuming it's the first channel)\n",
        "      y_true_no_bg = y_true[..., 1:]  # Keep only kidney and tumor channels\n",
        "      y_pred_no_bg = y_pred[..., 1:]  # Keep only kidney and tumor channels\n",
        "\n",
        "      # Class weights: kidney, tumor\n",
        "      class_weights = tf.constant([1.0, 5.0], dtype=tf.float32)\n",
        "\n",
        "      # Apply weights to each class channel\n",
        "      weighted_y_true = y_true_no_bg * tf.reshape(class_weights, [1, 1, 1, 1, -1])\n",
        "\n",
        "      # Calculate Tversky components only for kidney and tumor\n",
        "      smooth = 1e-6\n",
        "      y_true_pos = weighted_y_true\n",
        "      y_pred_pos = y_pred_no_bg\n",
        "\n",
        "      true_pos = tf.reduce_sum(y_true_pos * y_pred_pos, axis=[1, 2, 3])\n",
        "      false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos), axis=[1, 2, 3])\n",
        "      false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos, axis=[1, 2, 3])\n",
        "\n",
        "      alpha = 0.3\n",
        "      beta = 0.7\n",
        "\n",
        "      tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
        "      tversky_loss = 1 - tversky\n",
        "\n",
        "      # Apply focal component\n",
        "      focal_tversky = tf.pow(tversky_loss, gamma)\n",
        "\n",
        "      return tf.reduce_mean(focal_tversky)\n",
        "\n",
        "\n",
        "\n",
        "    # Compile model with all metrics\n",
        "    model.compile(\n",
        "        optimizer=optim,\n",
        "        loss=kidney_tumor_only_loss,\n",
        "        metrics=[\n",
        "            kidney_tumor_dice,\n",
        "            kidney_tumor_iou,\n",
        "            kidney_dice,\n",
        "            tumor_dice,\n",
        "            kidney_tumor_vol_sim,\n",
        "            kidney_tumor_hausdorff\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Setup callbacks\n",
        "    model_path = os.path.join(output_dir, f\"{model_name}\")\n",
        "    cache_model_path = f'{model_path}_temp.keras'\n",
        "    best_model_path = os.path.join(output_dir, f\"{model_name}_best.keras\")\n",
        "    epoch_model_path = os.path.join(output_dir, f\"{model_name}_epoch{{epoch:02d}}.keras\")\n",
        "\n",
        "    log_file = os.path.join(output_dir, f'history_{model_name}.csv')\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(cache_model_path, monitor='val_loss', verbose=1),\n",
        "        ModelCheckpoint(best_model_path, monitor='val_kidney_tumor_iou', verbose=1, save_best_only=True, mode='max'),\n",
        "        #ReduceLROnPlateau(monitor='val_kidney_tumor_iou', factor=0.9, patience=5, min_lr=1e-7, min_delta=1e-6, verbose=1, mode='max'),\n",
        "        CSVLogger(log_file, append=True),\n",
        "        EarlyStopping(monitor='val_kidney_tumor_iou', patience=patience, verbose=1, mode='max', restore_best_weights=True),\n",
        "    ]\n",
        "\n",
        "    # Fit model\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps=validation_steps,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    max_iou = max(history.history['val_kidney_tumor_iou'])\n",
        "    print(f'Training finished. Max Kidney-Tumor IoU: {max_iou:.4f}')\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Kidney-Tumor Dice coefficient\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.plot(history.history['kidney_tumor_dice'], label='Training Dice')\n",
        "    plt.plot(history.history['val_kidney_tumor_dice'], label='Validation Dice')\n",
        "    plt.title('Kidney-Tumor Dice Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Dice')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Kidney-Tumor IoU\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.plot(history.history['kidney_tumor_iou'], label='Training IoU')\n",
        "    plt.plot(history.history['val_kidney_tumor_iou'], label='Validation IoU')\n",
        "    plt.title('Kidney-Tumor IoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Kidney vs Tumor Dice\n",
        "    plt.subplot(2, 3, 4)\n",
        "    plt.plot(history.history['kidney_dice'], label='Kidney Dice')\n",
        "    plt.plot(history.history['val_kidney_dice'], label='Val Kidney Dice')\n",
        "    plt.plot(history.history['tumor_dice'], label='Tumor Dice')\n",
        "    plt.plot(history.history['val_tumor_dice'], label='Val Tumor Dice')\n",
        "    plt.title('Kidney vs Tumor Dice')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Dice')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Hausdorff distance\n",
        "    plt.subplot(2, 3, 5)\n",
        "    plt.plot(history.history['kidney_tumor_hausdorff'], label='Training Hausdorff')\n",
        "    plt.plot(history.history['val_kidney_tumor_hausdorff'], label='Val Hausdorff')\n",
        "    plt.title('Hausdorff Distance')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Distance')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Volumetric similarity\n",
        "    plt.subplot(2, 3, 6)\n",
        "    plt.plot(history.history['kidney_tumor_vol_sim'], label='Training Vol. Similarity')\n",
        "    plt.plot(history.history['val_kidney_tumor_vol_sim'], label='Val Vol. Similarity')\n",
        "    plt.title('Volumetric Similarity')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Similarity')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'{model_name}_history.png'))\n",
        "    plt.show()\n",
        "\n",
        "    # Save the best model\n",
        "    final_model_path = os.path.join(output_dir, f\"{model_name}_final.keras\")  # Final best model for deployment\n",
        "    model.save(final_model_path)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGzdmtwf7Cyn"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJXSqoS07Cyn"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/kits23/dataset/'\n",
        "output_dir = '/content/models'\n",
        "model_name = 'kits23_unet'\n",
        "batch_size = 8\n",
        "epochs = 128\n",
        "learning_rate = 0.0001\n",
        "patience = 40\n",
        "backbone = 'resnet18'  # You can try other backbones like 'resnet34', 'vgg16', etc.\n",
        "target_shape = (128, 128, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, history = train_kits23_model(\n",
        "    dataset_path=dataset_path,\n",
        "    output_dir=output_dir,\n",
        "    model_name=model_name,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    patience=patience,\n",
        "    backbone=backbone,\n",
        "    target_shape=target_shape\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12WYbGvV7Cyn"
      },
      "source": [
        "# Test Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLQDwNzN7Cyn"
      },
      "outputs": [],
      "source": [
        "def visualize_sample(dataset, case_id=None):\n",
        "    \"\"\"Visualize a sample case from the dataset with more detailed views\"\"\"\n",
        "    if case_id is None:\n",
        "        case_id = random.choice(dataset.cases)\n",
        "\n",
        "    print(f\"Visualizing case: {case_id}\")\n",
        "\n",
        "    # Load the case\n",
        "    image, mask = dataset.load_case(case_id)\n",
        "\n",
        "    # Get original files for inspection\n",
        "    imaging_path = dataset._get_imaging_path(case_id)\n",
        "    segmentation_path = dataset._get_segmentation_path(case_id)\n",
        "\n",
        "    print(f\"Original files: \\nImage: {imaging_path}\\nSegmentation: {segmentation_path}\")\n",
        "\n",
        "    # Load original data to check\n",
        "    try:\n",
        "        orig_img = dataset._load_nifti(imaging_path)\n",
        "        orig_seg = dataset._load_nifti(segmentation_path)\n",
        "        print(f\"Original image shape: {orig_img.shape}\")\n",
        "        print(f\"Original mask shape: {orig_seg.shape}\")\n",
        "        print(f\"Original mask unique values: {np.unique(orig_seg)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading original files: {e}\")\n",
        "\n",
        "    # Print processed data info\n",
        "    print(f\"Processed image shape: {image.shape}\")\n",
        "    print(f\"Processed mask shape: {mask.shape}\")\n",
        "\n",
        "    # Get multiple slice views (start, middle, end)\n",
        "    slice_indices = [\n",
        "        image.shape[0] // 4,\n",
        "        image.shape[0] // 2,\n",
        "        3 * image.shape[0] // 4\n",
        "    ]\n",
        "\n",
        "    # Create a figure with multiple views\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "\n",
        "    for row, slice_idx in enumerate(slice_indices):\n",
        "        # Show image\n",
        "        axes[row, 0].imshow(image[slice_idx, :, :, 0], cmap='gray')\n",
        "        axes[row, 0].set_title(f\"CT Slice {slice_idx}\")\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "        # Show segmentation as separate channels\n",
        "        # Background (class 0)\n",
        "        if mask.shape[-1] > 0:\n",
        "            axes[row, 1].imshow(mask[slice_idx, :, :, 0], cmap='Blues')\n",
        "            axes[row, 1].set_title(f\"Background (class 0)\")\n",
        "            axes[row, 1].axis('off')\n",
        "\n",
        "        # Combined kidney/tumor visualization with better colors\n",
        "        mask_img = np.zeros((*mask.shape[1:3], 3))\n",
        "        if mask.shape[-1] > 1:  # Kidney (class 1) - red\n",
        "            mask_img[:, :, 0] += mask[slice_idx, :, :, 1]\n",
        "        if mask.shape[-1] > 2:  # Tumor (class 2) - green\n",
        "            mask_img[:, :, 1] += mask[slice_idx, :, :, 2]\n",
        "\n",
        "        axes[row, 2].imshow(image[slice_idx, :, :, 0], cmap='gray')\n",
        "        axes[row, 2].imshow(mask_img, alpha=0.5)\n",
        "        axes[row, 2].set_title(f\"Overlay (red=kidney, green=tumor)\")\n",
        "        axes[row, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'visualization_{case_id}.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Also show some orthogonal views (sagittal and coronal)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "\n",
        "    # Middle slices in different orientations\n",
        "    mid_x = image.shape[1] // 2\n",
        "    mid_y = image.shape[2] // 2\n",
        "    mid_z = image.shape[0] // 2\n",
        "\n",
        "    # Coronal view (x-z plane)\n",
        "    axes[0, 0].imshow(image[:, mid_y, :, 0], cmap='gray')\n",
        "    axes[0, 0].set_title(\"Coronal CT View\")\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Sagittal view (y-z plane)\n",
        "    axes[0, 1].imshow(image[:, :, mid_x, 0], cmap='gray')\n",
        "    axes[0, 1].set_title(\"Sagittal CT View\")\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    # Axial view (x-y plane) - already shown above\n",
        "    axes[0, 2].imshow(image[mid_z, :, :, 0], cmap='gray')\n",
        "    axes[0, 2].set_title(\"Axial CT View\")\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    # Mask overlays for the same views\n",
        "    mask_img_coronal = np.zeros((image.shape[0], image.shape[2], 3))\n",
        "    mask_img_sagittal = np.zeros((image.shape[0], image.shape[1], 3))\n",
        "    mask_img_axial = np.zeros((image.shape[1], image.shape[2], 3))\n",
        "\n",
        "    if mask.shape[-1] > 1:  # Kidney (class 1)\n",
        "        mask_img_coronal[:, :, 0] = mask[:, mid_y, :, 1]\n",
        "        mask_img_sagittal[:, :, 0] = mask[:, :, mid_x, 1]\n",
        "        mask_img_axial[:, :, 0] = mask[mid_z, :, :, 1]\n",
        "\n",
        "    if mask.shape[-1] > 2:  # Tumor (class 2)\n",
        "        mask_img_coronal[:, :, 1] = mask[:, mid_y, :, 2]\n",
        "        mask_img_sagittal[:, :, 1] = mask[:, :, mid_x, 2]\n",
        "        mask_img_axial[:, :, 1] = mask[mid_z, :, :, 2]\n",
        "\n",
        "    # Show overlays\n",
        "    axes[1, 0].imshow(image[:, mid_y, :, 0], cmap='gray')\n",
        "    axes[1, 0].imshow(mask_img_coronal, alpha=0.5)\n",
        "    axes[1, 0].set_title(\"Coronal Mask Overlay\")\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    axes[1, 1].imshow(image[:, :, mid_x, 0], cmap='gray')\n",
        "    axes[1, 1].imshow(mask_img_sagittal, alpha=0.5)\n",
        "    axes[1, 1].set_title(\"Sagittal Mask Overlay\")\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    axes[1, 2].imshow(image[mid_z, :, :, 0], cmap='gray')\n",
        "    axes[1, 2].imshow(mask_img_axial, alpha=0.5)\n",
        "    axes[1, 2].set_title(\"Axial Mask Overlay\")\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'visualization_orthogonal_{case_id}.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9hSDEkm7Cyn"
      },
      "outputs": [],
      "source": [
        "# Initialize dataset for visualization\n",
        "dataset = KiTS23Dataset(dataset_path=dataset_path, target_shape=target_shape)\n",
        "visualize_sample(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhfsQh2j7Cyo"
      },
      "outputs": [],
      "source": [
        "! zip -r models.zip /content/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yirjoxOkpN8z"
      },
      "source": [
        "# Save Model to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ7n_nTDpRmP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def save_to_google_drive(model, model_dir, model_name, training_config, drive_folder=\"KiTS23_Models\"):\n",
        "    \"\"\"\n",
        "    Saves the trained model using the `model` variable, CSV history file, training plot,\n",
        "    and training config to Google Drive.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The trained Keras model to save.\n",
        "        model_dir (str): The directory where the model and logs are stored.\n",
        "        model_name (str): The base name of the model files (without extension).\n",
        "        training_config (dict): Dictionary containing training parameters.\n",
        "        drive_folder (str): The name of the folder in Google Drive to save files.\n",
        "\n",
        "    Returns:\n",
        "        str: The full path to the Google Drive folder.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1ï¸âƒ£ Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # 2ï¸âƒ£ Define the Google Drive path\n",
        "    drive_path = f\"/content/drive/My Drive/{drive_folder}\"\n",
        "\n",
        "    # Create folder if it doesn't exist\n",
        "    if not os.path.exists(drive_path):\n",
        "        os.makedirs(drive_path)\n",
        "\n",
        "    # 3ï¸âƒ£ Define file paths\n",
        "    model_path = os.path.join(model_dir, f\"{model_name}.keras\")  # Trained model file\n",
        "    history_csv = os.path.join(model_dir, f\"history_{model_name}.csv\")  # CSV file\n",
        "    history_png = os.path.join(model_dir, f\"{model_name}_history.png\")  # Plot image\n",
        "    config_txt = os.path.join(model_dir, f\"{model_name}_config.txt\")  # Training config\n",
        "\n",
        "    # 4ï¸âƒ£ Save the model using model.save()\n",
        "    print(\"ðŸ”„ Saving model...\")\n",
        "    model.save(model_path)  # âœ… This ensures the latest trained model is saved\n",
        "    print(f\"âœ… Model saved at: {model_path}\")\n",
        "\n",
        "    # 5ï¸âƒ£ Save training configuration as a text file\n",
        "    with open(config_txt, \"w\") as f:\n",
        "        for key, value in training_config.items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n",
        "    print(f\"âœ… Training config saved: {config_txt}\")\n",
        "\n",
        "    # 6ï¸âƒ£ Move files to Google Drive\n",
        "    for file_path in [model_path, history_csv, history_png, config_txt]:\n",
        "        if os.path.exists(file_path):\n",
        "            shutil.copy(file_path, drive_path)\n",
        "            print(f\"âœ… Saved {os.path.basename(file_path)} to Google Drive: {drive_path}\")\n",
        "\n",
        "    print(\"ðŸš€ All files successfully saved to Google Drive!\")\n",
        "\n",
        "    return drive_path  # Return the folder path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "416ePT82qjnE"
      },
      "outputs": [],
      "source": [
        "# Define training configuration\n",
        "training_config = {\n",
        "    \"dataset_path\": dataset_path,\n",
        "    \"output_dir\": output_dir,\n",
        "    \"model_name\": model_name,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": epochs,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"patience\": patience,\n",
        "    \"backbone\": backbone,\n",
        "    \"target_shape\": target_shape,\n",
        "}\n",
        "\n",
        "# Save model & logs to Google Drive\n",
        "#save_to_google_drive(model, output_dir, model_name, training_config, drive_folder=\"3dunet-31-march\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "i1lv7gPM7Cyd",
        "MG-ZLaeQ7Cyi",
        "L1_72oy216IJ",
        "SVm7SPsc7Cyj",
        "z4mSrNf87NPO",
        "BLZWVzuw7Cyj",
        "p0htgc9r7Cyk",
        "UvxrCp8P7Cyl",
        "aGzdmtwf7Cyn",
        "12WYbGvV7Cyn"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0403ae6667274d7293b45dbb2472a443": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19f19ba91c604ce4a636ce1d1d99203e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aebbf0997a84e97a0462e3db6fae47b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eaa76817874472fa1b3fbde02279c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c61c538e294073bf7b18162a2298f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bcb0f58249843549a06ac05e2b67628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eaa76817874472fa1b3fbde02279c6c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_40c61c538e294073bf7b18162a2298f8",
            "value": "Analyzingâ€‡labels:â€‡100%"
          }
        },
        "67b620daff9e40b68d3118771537626b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e93ab3c98e644e293a35d8541a5d21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d5fb1d136e4042aecb80a10084e7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aebbf0997a84e97a0462e3db6fae47b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0403ae6667274d7293b45dbb2472a443",
            "value": 5
          }
        },
        "a09ac6341f184254a20f40b9f802576b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f350616723a8405dbfa1bdbd7ea11d46",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e055cde3ab77478d95b84eda746b9df0",
            "value": "Analyzingâ€‡cases:â€‡100%"
          }
        },
        "afc2a9c8d7994eb2a4e9076d3db021e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e858b87dd31b433fb146f37aae9a69d4",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1631378c384960a81aa62d5bd88434",
            "value": 10
          }
        },
        "b5046a740c8a49059a1395af842a4939": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b2195f13834d67a57c865d4ed2c4ca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_67b620daff9e40b68d3118771537626b",
            "value": "â€‡5/5â€‡[00:34&lt;00:00,â€‡â€‡9.00s/it]"
          }
        },
        "c0f1cdda1bf64523bfc52bd025279b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e73b93348409484fada55b15fa00ee6d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6e93ab3c98e644e293a35d8541a5d21d",
            "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡37.35it/s]"
          }
        },
        "cd89a1a7c5c84c5a8b0b7d71c9ea6fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a09ac6341f184254a20f40b9f802576b",
              "IPY_MODEL_90d5fb1d136e4042aecb80a10084e7e7",
              "IPY_MODEL_b5046a740c8a49059a1395af842a4939"
            ],
            "layout": "IPY_MODEL_d3e7795847734e80bae0ff02b45063b2"
          }
        },
        "d3e7795847734e80bae0ff02b45063b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b2195f13834d67a57c865d4ed2c4ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de789f9efc234e6d98b6ce398f098f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bcb0f58249843549a06ac05e2b67628",
              "IPY_MODEL_afc2a9c8d7994eb2a4e9076d3db021e3",
              "IPY_MODEL_c0f1cdda1bf64523bfc52bd025279b03"
            ],
            "layout": "IPY_MODEL_19f19ba91c604ce4a636ce1d1d99203e"
          }
        },
        "e055cde3ab77478d95b84eda746b9df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e73b93348409484fada55b15fa00ee6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e858b87dd31b433fb146f37aae9a69d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea1631378c384960a81aa62d5bd88434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f350616723a8405dbfa1bdbd7ea11d46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
